{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 \n",
    "#### Name : Dnyanai Surkutwar\n",
    "#### Email: dsurkutwar@scu.edu\n",
    "\n",
    "\n",
    "df2 = https://data.wprdc.org/dataset/7fb0505e-8e2c-4825-b22c-4fbee8fc8010/resource/2d963e35-4f69-495e-985e-55acd72c87ca/download/crimelabaccidentaldrugdeathsextract2017.csv: refers to the accidental deaths in CT state.\n",
    "\n",
    "df1 = https://data.ct.gov/api/views/rybz-nyjw/rows.csv?accessType=DOWNLOAD : refers to the the Allegheny county Drug related deaths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from functools import reduce\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./Accidental_Drug_Related_Deaths_2012-2018.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:\n",
    "### 1) Replacing the N/Y values with 0/1\n",
    "### 2) Making the datatypes uniform in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are changing the Y values in the cols to 1 and NaN to 0.\n",
    "df1.replace('Y',1,inplace=True) # Replaces Y to 1 and inplace makes the change permanent to the df\n",
    "df1.fillna(0,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Date'] = pd.to_datetime(df1['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Time'] = df1['Date'].dt.time\n",
    "df1.drop(['Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Year']= df1['Date'].dt.year.astype('Int64')\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to change the columns of float to int as its unecc.\n",
    "df1.Age = df1.Age.astype('int64')\n",
    "df1.Heroin= df1.Heroin.astype('int64')\n",
    "df1.Cocaine = df1.Cocaine.astype('int64')\n",
    "df1.FentanylAnalogue = df1.FentanylAnalogue.astype('int64')\n",
    "df1.Oxycodone = df1.Oxycodone.astype('int64')\n",
    "df1.Oxymorphone = df1.Oxymorphone.astype('int64')\n",
    "df1.Ethanol = df1.Ethanol.astype('int64')\n",
    "df1.Hydrocodone = df1.Hydrocodone.astype('int64')\n",
    "df1.Benzodiazepine = df1.Benzodiazepine.astype('int64')\n",
    "df1.Methadone = df1.Methadone.astype('int64')\n",
    "df1.Amphet = df1.Amphet.astype('int64')\n",
    "df1.Tramad = df1.Tramad.astype('int64')\n",
    "df1.Hydromorphone = df1.Hydromorphone.astype('int64')\n",
    "df1.OpiateNOS = df1.OpiateNOS.astype('int64')\n",
    "df1.Race = df1.Race.astype('str')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some unknown and 0 values in this dataframe because of which\n",
    "#the graphs are not properly plotted.,lets remove those.\n",
    "\n",
    "df1.drop(df1[(df1['Sex'].values=='Unknown')].index,axis=0,inplace=True)\n",
    "df1.drop(df1[(df1['Sex'].values==0)].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our data is specificaly from 2012 to 2018 so remove the datapoint \n",
    "#which is not in this range and maybe wrong/redundant.\n",
    "\n",
    "df1.drop(df1[(df1['Year'].values==1970)].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting everything to lower as we have many str values thus to \n",
    "#avoid errors we make everything in lowercase. \n",
    "df1['DeathCity'] = df1['DeathCity'].str.lower()\n",
    "df1['ResidenceCity'] = df1['ResidenceCity'].str.lower()\n",
    "df1['ResidenceCounty'] = df1['ResidenceCounty'].str.lower()\n",
    "df1['DeathCounty'] = df1['DeathCounty'].str.lower()\n",
    "df1['Location'] = df1['Location'].str.lower()\n",
    "df1['DescriptionofInjury'] = df1['DescriptionofInjury'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are still few cols which are not int64, so need to convert them.\n",
    "\n",
    "##Since bool objects cannot be replaced, need to convert to str then int\n",
    "## Y-A, Y POPS are all in teh dataset, converting it to 1\n",
    "df1.Fentanyl = df1.Fentanyl.astype('str')\n",
    "df1['Fentanyl'].replace(['Y-A','Y POPS','Y (PTCH)'],1,inplace=True)\n",
    "df1.Fentanyl = df1.Fentanyl.astype('int64')\n",
    "\n",
    "##Chaning and replacing for Morphine_Heroin\n",
    "df1.Morphine_NotHeroin = df1.Morphine_NotHeroin.astype('str')\n",
    "df1.Morphine_NotHeroin.replace(['YES','STOLE MEDS','NO RX BUT STRAWS','PCP NEG'],1,inplace=True)\n",
    "df1.Morphine_NotHeroin.replace('N',0,inplace=True)\n",
    "df1.Morphine_NotHeroin = df1.Morphine_NotHeroin.astype('int64')\n",
    "\n",
    "##For AnyOpioid\n",
    "df1.AnyOpioid = df1.AnyOpioid.astype('str')\n",
    "df1.AnyOpioid.replace('N',0,inplace=True)\n",
    "df1.AnyOpioid = df1.AnyOpioid.astype('int64')\n",
    "\n",
    "df1.dtypes\n",
    "\n",
    "##As per our steps earlier, we have to again remove 1970 year from the \n",
    "## column year as we are primarily foucusing on 2012-2018\n",
    "df1.drop(df1[(df1['Year'].values==1970)].index,axis=0,inplace=True)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here, we are creating a concatmask to identify which drug was involved.\n",
    "##Thus, we just convert every column to str and concat it to the next drug col value.\n",
    "\n",
    "df1['ConcatResult'] = df1.Heroin.astype(str)+df1.Cocaine.astype(str)+df1.Fentanyl.astype(str)+\\\n",
    "df1.FentanylAnalogue.astype(str)+df1.Oxycodone.astype(str)+df1.Oxymorphone.astype(str)+\\\n",
    "df1.Ethanol.astype(str)+df1.Hydrocodone.astype(str)+df1.Benzodiazepine.astype(str)+\\\n",
    "df1.Methadone.astype(str)+df1.Amphet.astype(str)+df1.Tramad.astype(str)+df1.Morphine_NotHeroin.astype(str)+\\\n",
    "df1.Hydromorphone.astype(str)+df1.OpiateNOS.astype(str)+df1.AnyOpioid.astype(str)\n",
    "\n",
    "df1['NumberOfDrugs'] = df1.Heroin+df1.Cocaine+df1.Fentanyl+df1.FentanylAnalogue+df1.Oxycodone+\\\n",
    "df1.Oxymorphone+df1.Ethanol+df1.Hydrocodone+df1.Benzodiazepine+df1.Methadone+\\\n",
    "df1.Amphet+df1.Tramad+df1.Morphine_NotHeroin+df1.Hydromorphone+df1.OpiateNOS+df1.AnyOpioid\n",
    "\n",
    "##Here we created and added two new columns to df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Doing classification using decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Interesting Fact 1: \n",
    "### Classification model is a supervised model which is used to predict the next possible data point based on what is your target variable and what independent variables it depends on.\n",
    "### The accuracy of the model below is 32% which is not too good, this can be adjusted by tuning the parameters and optimizing the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a new dataset and taking only those columns which we need to look at\n",
    "df2 = df1[['Sex','Age','Heroin','Cocaine','NumberOfDrugs']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification library import\n",
    "import sklearn as sk\n",
    "import sklearn.tree as tree\n",
    "from IPython.display import Image  \n",
    "import pydotplus \n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making dummies for the other columns besides the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df2, columns=['Sex','Age','Heroin','Cocaine'],dummy_na=False) ##getdummies creates 1/0 dummy values \n",
    "##for all categorial/numerical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will divide our dataset into training and testing data and first train it and then test it on a new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('NumberOfDrugs',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.NumberOfDrugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the classifier\n",
    "dt = tree.DecisionTreeClassifier(max_depth=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "roundNo = round((metrics.accuracy_score(y_test, y_pred)*100),2)\n",
    "print(\"Accuracy:\",roundNo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will visualize a decision tree dt, trained with the attributes in X and the class labels in Y\n",
    "dt_feature_names = list(X.columns) #Converting the independent variables to a list \n",
    "dt_target_names = [str(s) for s in Y.unique()] #take unique values of Y i.e. DogName\n",
    "tree.export_graphviz(dt, out_file='tree.dot', \n",
    "    feature_names=dt_feature_names, class_names=dt_target_names,\n",
    "    filled=True)  \n",
    "graph = pydotplus.graph_from_dot_file('tree.dot') #generating a tree\n",
    "graph.set_size('\"20,25!\"')\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Interesting Fact 2: \n",
    "###  The hartford city & hartford county has the highest number of death contributing almost 31% of the entire states drug related deaths.Also, gender wise precentage for hartford city alone is 2.34% Male involving 2 and 3 drugs. The city death has highest number of whites. \n",
    "### The hartford city has an all time high count since 2016, increasing each year by 11-12% since 2016. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df3 = df1[['Year','Age','Sex','Race','DeathCity','ResidenceCity','NumberOfDrugs']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the above columns we are checking for na and dropping them if they are insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.Age.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.Sex.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.Race.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RseidenceCity Total: ',df3.ResidenceCity.size)\n",
    "print('ResidenceCity null/NaN values: ',df3.ResidenceCity.isna().sum())\n",
    "### Thus, we are deleting them \n",
    "df3.ResidenceCity.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RseidenceCity Total: ',df3.DeathCity.size)\n",
    "print('ResidenceCity null/NaN values: ',df3.DeathCity.isna().sum())\n",
    "### Thus, we are deleting them \n",
    "df3.DeathCity.dropna(inplace=True)\n",
    "df3.drop(df1[(df1['DeathCity'].values=='06340')].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are finding out which DeathCity is the highest in which year\n",
    "df3.groupby('DeathCity')['Year'].value_counts().nlargest(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the above findings\n",
    "df3.groupby('DeathCity')['Year'].value_counts().nlargest(10).unstack().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we are finding out the max @ hartford for NumberofDrugs involved according to their sex, we are taking out the %\n",
    "total = df3.DeathCity.count()\n",
    "round(((df3[df3.DeathCity=='hartford'].groupby('NumberOfDrugs')['Sex'].value_counts().nlargest(5)/total)*100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are finding out the dominant race in the deaths recorded.\n",
    "df3[df3.DeathCity=='hartford'].Race.value_counts().nlargest(5).plot(kind='bar')\n",
    "print('The race with the highest death count is: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df1.DeathCounty.value_counts()/df1.DeathCounty.count()*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Interesting fact 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets do a clustering model and find out which is the race with the higest involvement with the highest drug related deaths.\n",
    "\n",
    "### Clustering is an unsupervised algorithm which groups similar data points together an aims to increase inter cluster distance and decrease intra cluster distance. \n",
    "\n",
    "### As per our observations below, the White race is predominantly present in all cluster labels, this tells us that almost all kinds of age and Sex data points have similarity with the \"White\" race. Moreover, we also see how the clusters are divided based on the deceased ages, and cluster number 4 & 2 refering to ages 54-74yrs & 14-32yrs are the most dominant ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy variables for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping a vlue which is invalid for Race\n",
    "#df3.drop(df1[(df1['DeathCity'].values=='06340')].index,axis=0,inplace=True)\n",
    "df3.drop(df3[(df3['Race'].values =='0')].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables for the DogName column values.\n",
    "data = pd.get_dummies(df3)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we are importing the scikit-learn modules to use in K-Mean Clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "bestSil = -1\n",
    "for k in range(2,6):\n",
    "    print ('k= %d ' % k)\n",
    "    #We are using the KMeans clustering model\n",
    "    clus = [KMeans(n_clusters=k)]\n",
    "    for cl in clus:\n",
    "        res = cl.fit(data) #Here, we are fitting the model here to get accurate values\n",
    "        sil = metrics.silhouette_score(data, res.labels_)#Generate the silhouette coefficient \n",
    "        print (str(cl)[:6] + ' with k=' +str(k) + \": \" + str(round(sil,4)))\n",
    "        if (sil > bestSil):\n",
    "            bestSil = sil\n",
    "            bestCl = cl\n",
    "            bestK = k\n",
    "print('***********************************************')\n",
    "print ('Best output is with k=' +str(bestK) )\n",
    "print('**********************')\n",
    "print ('With Silhouette Score ' + str(round(bestSil,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Cluster_labels'] = cl.labels_+1 ##Adding 1 to begin it from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby('Cluster_labels')['Race'].value_counts().nlargest(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Cluster_labels\", y=\"Age\", data=df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the above graph, we see that the cluster labels have clear age limits defined. \n",
    "### Cluster 1 is refering to ages 48-58yrs,\n",
    "### Cluster 2 is refering to ages 15-32yrs,\n",
    "### Cluster 3 is refering to ages 32-40yrs,\n",
    "### Cluster 4 is refering to ages 56-76yrs,\n",
    "### Cluster 5 is refering to ages 39-48yrs.\n",
    "### As we can observe, the maximum death age lies in Cluster 2 & 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(y='Race', data=df3, x='Age',\\\n",
    "               aspect=2, kind='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a new dataframe into ds about allengheny county for year 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('./crimelabaccidentaldrugdeathsextract2017.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pd.to_datetime converts to datetime\n",
    "ds['Death Date'] = pd.to_datetime(ds['Death Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Heroin'] = ds['Combined OD1'][ds['Combined OD1'] == 'Heroin'].apply(lambda x:1 if (x=='Heroin') else (0))\n",
    "ds['Cocaine'] = ds['Combined OD1'][ds['Combined OD1'] == 'Cocaine'].apply(lambda x:1 if (x=='Cocaine') else (0))\n",
    "ds.fillna(0,inplace=True)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to 1 for every column having Heroin or Cocaine in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Heroin'].loc[ds['Combined OD2']=='Heroin'] = 1\n",
    "ds['Heroin'].loc[ds['Combined OD3']=='Heroin'] = 1\n",
    "ds['Heroin'].loc[ds['Combined OD4']=='Heroin'] = 1\n",
    "ds['Heroin'].loc[ds['Combined OD5']=='Heroin'] = 1\n",
    "ds['Heroin'].loc[ds['Combined OD6']=='Heroin'] = 1\n",
    "ds['Heroin'].loc[ds['Combined OD7']=='Heroin'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Cocaine'].loc[ds['Combined OD2']=='Cocaine'] = 1\n",
    "ds['Cocaine'].loc[ds['Combined OD3']=='Cocaine'] = 1\n",
    "ds['Cocaine'].loc[ds['Combined OD4']=='Cocaine'] = 1\n",
    "ds['Cocaine'].loc[ds['Combined OD5']=='Cocaine'] = 1\n",
    "ds['Cocaine'].loc[ds['Combined OD6']=='Cocaine'] = 1\n",
    "ds['Cocaine'].loc[ds['Combined OD7']=='Cocaine'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Heroin = ds.Heroin.astype('Int64')\n",
    "ds.Cocaine = ds.Cocaine.astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a new year column for df2 to access only the year\n",
    "ds['Year']= ds['Death Date'].dt.year.astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After data preparation we will merge the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = ds[['Year','Age','Sex','Race','Heroin','Cocaine']].copy()\n",
    "print(ds1.shape)\n",
    "ds1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These two datasets are not ideal for merging as Year is the only column in common. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge = df5.merge(ds1,left_on='Year',right_on='Year',how='inner').drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
